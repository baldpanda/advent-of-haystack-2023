{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baldpanda/advent-of-haystack-2023/blob/main/day_2/advent_of_haystack_day_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advent of Haystack - Day 2\n",
        "_Make a copy of this Colab to start!_\n",
        "\n",
        "\n",
        "In this challenge, you will complete a scavenger hunt prepared by the Haystack elves. Find what their favorite animals is!!\n",
        "\n",
        "- [`LinkContentFetcher`](https://docs.haystack.deepset.ai/v2.0/docs/linkcontentfetcher): This will allow you to fetch the contents of https://haystack.deepset.ai/advent-of-haystack/day-1#challenge\n",
        "- [`HTMLToDocument`](https://docs.haystack.deepset.ai/v2.0/docs/htmltodocument): Once you've fetched the contents, this component will allow you to convert it to a Document\n",
        "- [`DocumentSplitter`](https://docs.haystack.deepset.ai/v2.0/docs/documentsplitter) (Optional): This is useful if you want to split your Document into chunks\n",
        "- [`TransformersSimilarityRanker`](https://docs.haystack.deepset.ai/v2.0/docs/transformerssimilarityranker) (Optional): This is useful if you want to rank your documents (chunked with the splitter above) so that the most relevant is at the top.\n",
        "- [`PromptBuilder`](https://docs.haystack.deepset.ai/v2.0/docs/promptbuilder): This is used to define how you want to prompr an LLM so that it generates an accurate response for you. We’ve included one for you in the starter Colab that will help you with this challenge.\n",
        "- [`GPTGenerator`](https://docs.haystack.deepset.ai/v2.0/docs/gptgenerator): This component is used to query GPT. You can change this to one of our other generators instead!"
      ],
      "metadata": {
        "id": "9aQZbzmu5RhN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installation\n",
        "**Note:** There is a known issue with colab due to a version conflict error related to `llmx` which comes with Colab. You might get an `llmx` error. You can safely ignore this, or run `pip uninstall -y llmx`"
      ],
      "metadata": {
        "id": "StheMrF6WChd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vsK2E3oCpm3b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef582895-01d3-498b-f9dc-e7532b044000"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting haystack-ai\n",
            "  Downloading haystack_ai-2.0.0b2-py3-none-any.whl (185 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 185.7/185.7 kB 2.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.1.2)\n",
            "Collecting lazy-imports (from haystack-ai)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.2.1)\n",
            "Collecting openai<1.0.0 (from haystack-ai)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 77.0/77.0 kB 12.7 MB/s eta 0:00:00\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (1.5.3)\n",
            "Collecting posthog (from haystack-ai)\n",
            "  Downloading posthog-3.1.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (6.0.1)\n",
            "Collecting rank-bm25 (from haystack-ai)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<1.0.0->haystack-ai) (2.31.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<1.0.0->haystack-ai) (3.9.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->haystack-ai) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->haystack-ai) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->haystack-ai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->haystack-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1.0.0->haystack-ai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1.0.0->haystack-ai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1.0.0->haystack-ai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1.0.0->haystack-ai) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (4.0.3)\n",
            "Installing collected packages: monotonic, rank-bm25, lazy-imports, backoff, posthog, openai, haystack-ai\n",
            "Successfully installed backoff-2.2.1 haystack-ai-2.0.0b2 lazy-imports-0.3.1 monotonic-1.6 openai-0.28.1 posthog-3.1.0 rank-bm25-0.2.2\n",
            "Collecting boilerpy3\n",
            "  Downloading boilerpy3-1.0.7-py3-none-any.whl (22 kB)\n",
            "Installing collected packages: boilerpy3\n",
            "Successfully installed boilerpy3-1.0.7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\n"
          ]
        }
      ],
      "source": [
        "%%bash\n",
        "pip install haystack-ai\n",
        "pip install boilerpy3\n",
        "pip install transformers[torch,sentencepiece]==4.32.1 sentence-transformers>=2.2.0"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run this code and you’ll be prompted to enter your openAI credentials. If you don’t have a key, [follow these instructions](https://help.openai.com/en/articles/4936850-where-do-i-find-my-api-key)."
      ],
      "metadata": {
        "id": "bhilvHQIrf2X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "openai_api_key = userdata.get('openai_api_key')"
      ],
      "metadata": {
        "id": "kVUhdPXea8Wh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a Pipeline to fetch the contents of a webpage\n",
        "\n",
        "Complete the code cell below to create a pipeline that fetches the contents from  https://haystack.deepset.ai/advent-of-haystack/day-1#challenge"
      ],
      "metadata": {
        "id": "G4fnirIbcvDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.components.fetchers.link_content import LinkContentFetcher\n",
        "from haystack.components.converters import HTMLToDocument\n",
        "from haystack.components.preprocessors import DocumentSplitter\n",
        "from haystack.components.rankers import TransformersSimilarityRanker\n",
        "from haystack.components.generators import GPTGenerator\n",
        "from haystack.components.builders.prompt_builder import PromptBuilder\n",
        "from haystack import Pipeline\n",
        "\n",
        "\n",
        "prompt_template = \"\"\"\n",
        "According to these documents:\n",
        "\n",
        "{% for doc in documents %}\n",
        "  {{ doc.content }}\n",
        "{% endfor %}\n",
        "\n",
        "Answer the given question: {{question}}\n",
        "Answer:\n",
        "\"\"\"\n",
        "prompt_builder = PromptBuilder(template=prompt_template)\n",
        "\n",
        "pipeline = Pipeline()"
      ],
      "metadata": {
        "id": "35tdUVgfYFi1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm = GPTGenerator(api_key = openai_api_key, model_name = \"gpt-4\")\n",
        "fetcher = LinkContentFetcher()\n",
        "converter = HTMLToDocument()\n",
        "splitter = DocumentSplitter(split_length=100, split_overlap=5)"
      ],
      "metadata": {
        "id": "uZnzR-5FXsvf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.add_component(name=\"fetcher\", instance=fetcher)\n",
        "pipeline.add_component(name=\"converter\", instance=converter)\n",
        "pipeline.add_component(name=\"splitter\", instance=splitter)\n",
        "pipeline.add_component(name=\"prompt_builder\", instance=prompt_builder)\n",
        "pipeline.add_component(name=\"llm\", instance=llm)"
      ],
      "metadata": {
        "id": "hfz8VsHcXK63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline.connect(\"fetcher\", \"converter\")\n",
        "pipeline.connect(\"converter\", \"splitter\")\n",
        "pipeline.connect(\"splitter\", \"prompt_builder\")\n",
        "pipeline.connect(\"prompt_builder\", \"llm\")"
      ],
      "metadata": {
        "id": "XqI06-gqX-CS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Try to find the answer to the question\n",
        "\n"
      ],
      "metadata": {
        "id": "kKbmWPWvcaP0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"What is our favorite animal?\"\n",
        "result = pipeline.run({\"prompt_builder\": {\"question\": question}, \"fetcher\": {\"urls\": [\"https://haystack.deepset.ai/advent-of-haystack/day-1#challenge\"]}})\n",
        "\n",
        "print(result['llm']['replies'][0])"
      ],
      "metadata": {
        "id": "fk-LYY5vbVjf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dbd165d-c36a-4d2d-9a8f-9285785aa890"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The favorite animal is a capybara.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yJpW1QgVYIzD"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
