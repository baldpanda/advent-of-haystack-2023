{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e68f33fbf9f84c9f92ff0fc6fafd8323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_908f7805dea54fa69085d8055252a72a",
              "IPY_MODEL_86d44dc2796c4904a03206dbacb7f7f1",
              "IPY_MODEL_2b8551659a7442d1bfcb3a44d0369dbb"
            ],
            "layout": "IPY_MODEL_0f7aaa44361244e98126290da37b8294"
          }
        },
        "908f7805dea54fa69085d8055252a72a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a91cec66f9904e28ba35c507c04db8d7",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_56adb25db60b4acf86c57ecb91664d1a",
            "value": "Ranking by BM25...: 100%"
          }
        },
        "86d44dc2796c4904a03206dbacb7f7f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02e2b0b58fcc47f88903069ae0abf0d9",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_db944896433d4167bc837071380fcaeb",
            "value": 1
          }
        },
        "2b8551659a7442d1bfcb3a44d0369dbb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5ef5ab47d4f54276ab20a26c77505be9",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c558e0d6cc924944a0752c3579d11b1d",
            "value": " 1/1 [00:00&lt;00:00, 64.51 docs/s]"
          }
        },
        "0f7aaa44361244e98126290da37b8294": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a91cec66f9904e28ba35c507c04db8d7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56adb25db60b4acf86c57ecb91664d1a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02e2b0b58fcc47f88903069ae0abf0d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "db944896433d4167bc837071380fcaeb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5ef5ab47d4f54276ab20a26c77505be9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c558e0d6cc924944a0752c3579d11b1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baldpanda/advent-of-haystack-2023/blob/main/day_5/advent_of_haystack_day_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Advent of Haystack - Day 5\n",
        "_Make a copy of this Colab to start!_\n",
        "\n",
        "Here, you'll be provided with a document store containing some documents and their metadata. Our aim is to create a querying pipeline that uses these metadata to filter documents when we run the pipeline.\n",
        "\n",
        "1. **Write documents to a document store:** This is already complete. Here, we are writing documents and their metadata into an `InMemoryDocumentStore`.\n",
        "2. **Your task is to complete step 2 üëá**\n",
        "\n",
        "**Useful documentation:**\n",
        "\n",
        "-  [Metadata Filtering](https://docs.haystack.deepset.ai/v2.0/docs/metadata-filtering)\n",
        "- [`InMemoryBM25Retriever`](https://docs.haystack.deepset.ai/v2.0/docs/inmemorybm25retriever)\n",
        "- [`Pipelines`](https://docs.haystack.deepset.ai/v2.0/docs/creating-pipelines)"
      ],
      "metadata": {
        "id": "Vy662IFj_9Pl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Installation\n",
        "**Note:** There is a known issue with colab due to a version conflict error related to `llmx` which comes with Colab. You might get an `llmx` error. You can safely ignore this, or run `pip uninstall -y llmx`"
      ],
      "metadata": {
        "id": "S8bnjlbvXXcm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FNJ76BOtRPKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69602d14-1ff1-425c-e34c-d0acfcbf089c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting haystack-ai\n",
            "  Downloading haystack_ai-2.0.0b2-py3-none-any.whl (185 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m185.7/185.7 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.1.2)\n",
            "Collecting lazy-imports (from haystack-ai)\n",
            "  Downloading lazy_imports-0.3.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (10.1.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (3.2.1)\n",
            "Collecting openai<1.0.0 (from haystack-ai)\n",
            "  Downloading openai-0.28.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m77.0/77.0 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (1.5.3)\n",
            "Collecting posthog (from haystack-ai)\n",
            "  Downloading posthog-3.1.0-py2.py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (6.0.1)\n",
            "Collecting rank-bm25 (from haystack-ai)\n",
            "  Downloading rank_bm25-0.2.2-py3-none-any.whl (8.6 kB)\n",
            "Requirement already satisfied: tenacity in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (8.2.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from haystack-ai) (4.5.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.10/dist-packages (from openai<1.0.0->haystack-ai) (2.31.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from openai<1.0.0->haystack-ai) (3.9.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->haystack-ai) (2.1.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (2023.3.post1)\n",
            "Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas->haystack-ai) (1.23.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog->haystack-ai) (1.16.0)\n",
            "Collecting monotonic>=1.5 (from posthog->haystack-ai)\n",
            "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
            "Collecting backoff>=1.10.0 (from posthog->haystack-ai)\n",
            "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1.0.0->haystack-ai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1.0.0->haystack-ai) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1.0.0->haystack-ai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.20->openai<1.0.0->haystack-ai) (2023.11.17)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (1.9.3)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->openai<1.0.0->haystack-ai) (4.0.3)\n",
            "Installing collected packages: monotonic, rank-bm25, lazy-imports, backoff, posthog, openai, haystack-ai\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires tiktoken, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed backoff-2.2.1 haystack-ai-2.0.0b2 lazy-imports-0.3.1 monotonic-1.6 openai-0.28.1 posthog-3.1.0 rank-bm25-0.2.2\n"
          ]
        }
      ],
      "source": [
        "!pip install haystack-ai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Enabling Telemetry\n",
        "\n",
        "Knowing you‚Äôre running this challenge helps us know whether Advent of Haystack is helping people learn about Haystack 2.0-Beta. But you can always opt out by commenting the following line."
      ],
      "metadata": {
        "id": "OfU7XmzQz3qb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.telemetry import tutorial_running\n",
        "\n",
        "tutorial_running(\"challenge_5\")"
      ],
      "metadata": {
        "id": "GlTkf0kez20p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Write Documents to InMemoryDocumentStore\n",
        "\n",
        "Here, we are writing the contents of a few URLs into an `InMemoryDocumentStore`"
      ],
      "metadata": {
        "id": "217qjo-yOhrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack import Pipeline, Document\n",
        "from haystack.document_stores import InMemoryDocumentStore\n",
        "from haystack.components.retrievers import InMemoryBM25Retriever\n",
        "\n",
        "documents = [Document(content=\"Use pip to install a basic version of Haystack's latest release: pip install farm-haystack. All the core Haystack components live in the haystack repo. But there's also the haystack-extras repo which contains components that are not as widely used, and you need to install them separately.\",\n",
        "                      meta={\"version\": \"1.15\"}),\n",
        "             Document(content=\"Use pip to install a basic version of Haystack's latest release: pip install farm-haystack[inference]. All the core Haystack components live in the haystack repo. But there's also the haystack-extras repo which contains components that are not as widely used, and you need to install them separately.\",\n",
        "                      meta={\"version\": \"1.22\"}),\n",
        "             Document(content=\"Use pip to install only the Haystack 2.0 code: pip install haystack-ai. The haystack-ai package is built on the main branch which is an unstable beta version, but it's useful if you want to try the new features as soon as they are merged.\",\n",
        "                      meta={\"version\": \"2.0\"}),\n",
        "]\n",
        "document_store = InMemoryDocumentStore()\n",
        "document_store.write_documents(documents=documents)\n"
      ],
      "metadata": {
        "id": "N9881vPcOsQE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3c72eade-2bed-4bdf-816f-841f54e21c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) Build a Querying Pipeline\n",
        "Here, we have provided a nearly complete querying pipeline, but it doesn't use metadata for filtering yet. Make sure your `InMemoryBM25Retriever` filters documents based on their metadata when you send a query. That way, you can limit the list of retrieved documents to the ones that fulfill the filtering condition! In this example, let's retrieve documents that have a version of 2.0."
      ],
      "metadata": {
        "id": "IlnOCH7ITpg4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline()\n",
        "pipeline.add_component(instance=InMemoryBM25Retriever(document_store=document_store), name=\"retriever\")"
      ],
      "metadata": {
        "id": "WOTZW1ja_8L5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(pipeline.run)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VHwlzl28lawn",
        "outputId": "7c5fdb5c-7fed-44cd-e78d-a696ae2b211a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on method run in module haystack.pipeline:\n",
            "\n",
            "run(data: Dict[str, Any], debug: bool = False) -> Dict[str, Any] method of haystack.pipeline.Pipeline instance\n",
            "    Runs the pipeline with given input data.\n",
            "    \n",
            "    :param data: A dictionary of inputs for the pipeline's components. Each key is a component name\n",
            "    and its value is a dictionary of that component's input parameters.\n",
            "    :param debug: Set to True to collect and return debug information.\n",
            "    :return: A dictionary containing the pipeline's output.\n",
            "    :raises PipelineRuntimeError: If a component fails or returns unexpected output.\n",
            "    \n",
            "    Example a - Using named components:\n",
            "    Consider a 'Hello' component that takes a 'word' input and outputs a greeting.\n",
            "    \n",
            "    ```python\n",
            "    @component\n",
            "    class Hello:\n",
            "        @component.output_types(output=str)\n",
            "        def run(self, word: str):\n",
            "            return {\"output\": f\"Hello, {word}!\"}\n",
            "    ```\n",
            "    \n",
            "    Create a pipeline with two 'Hello' components connected together:\n",
            "    \n",
            "    ```python\n",
            "    pipeline = Pipeline()\n",
            "    pipeline.add_component(\"hello\", Hello())\n",
            "    pipeline.add_component(\"hello2\", Hello())\n",
            "    pipeline.connect(\"hello.output\", \"hello2.word\")\n",
            "    result = pipeline.run(data={\"hello\": {\"word\": \"world\"}})\n",
            "    ```\n",
            "    \n",
            "    This runs the pipeline with the specified input for 'hello', yielding\n",
            "    {'hello2': {'output': 'Hello, Hello, world!!'}}.\n",
            "    \n",
            "    Example b - Using flat inputs:\n",
            "    You can also pass inputs directly without specifying component names:\n",
            "    \n",
            "    ```python\n",
            "    result = pipeline.run(data={\"word\": \"world\"})\n",
            "    ```\n",
            "    \n",
            "    The pipeline resolves inputs to the correct components, returning\n",
            "    {'hello2': {'output': 'Hello, Hello, world!!'}}.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"Haystack installation\"\n",
        "result = pipeline.run(data={\n",
        "    \"retriever\" : { \"query\": query, \"filters\":\n",
        "     { \"operator\": \"AND\",\n",
        "      \"conditions\": [{\"field\": \"meta.version\", \"operator\": \"==\", \"value\": \"2.0\"},]\n",
        "    \t\t\t   }\n",
        "     }})"
      ],
      "metadata": {
        "id": "0ER1Sv1ZAu_Q",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "e68f33fbf9f84c9f92ff0fc6fafd8323",
            "908f7805dea54fa69085d8055252a72a",
            "86d44dc2796c4904a03206dbacb7f7f1",
            "2b8551659a7442d1bfcb3a44d0369dbb",
            "0f7aaa44361244e98126290da37b8294",
            "a91cec66f9904e28ba35c507c04db8d7",
            "56adb25db60b4acf86c57ecb91664d1a",
            "02e2b0b58fcc47f88903069ae0abf0d9",
            "db944896433d4167bc837071380fcaeb",
            "5ef5ab47d4f54276ab20a26c77505be9",
            "c558e0d6cc924944a0752c3579d11b1d"
          ]
        },
        "outputId": "76e6915f-0002-4f7d-d41a-bc21ed3cd0b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Ranking by BM25...:   0%|          | 0/1 [00:00<?, ? docs/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e68f33fbf9f84c9f92ff0fc6fafd8323"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zoa5mxSfloDt",
        "outputId": "4726b0dd-0ed3-4dee-8ab1-a738b608ccc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'retriever': {'documents': [Document(id=03311fb024425a57af746d1e75273a4376444e8c72e2a553d39a875714238dad, content: 'Use pip to install only the Haystack 2.0 code: pip install haystack-ai. The haystack-ai package is b...', meta: {'version': '2.0'}, score: -0.457755120278379)]}}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "utvE_lzfmuk4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}